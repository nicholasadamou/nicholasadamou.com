---
title: "Trading Space for Time: Boosting Algorithm Efficiency"
summary: "Explore how trading space for time can significantly improve the efficiency of an algorithm using a practical example of counting bad pairs in an array."
date: 2025-02-09
pinned: true
image_author: "Alex Shuper"
image_author_url: "https://unsplash.com/@alexshuperart"
image_url: "https://unsplash.com/photos/a-man-in-a-space-suit-with-a-sky-background-JYJwrUIDnL0"
---

When solving algorithmic problems, efficiency is often a balancing act between time complexity and space complexity. One powerful strategy is **trading space for time**. Let’s explore how this concept can help optimize a brute-force solution for counting "bad pairs" in a list. You can find this problem [here](https://leetcode.com/problems/count-number-of-bad-pairs).

## Table of Contents

## The Brute-Force Approach

The brute-force solution is quite simple but becomes insufficient for large input sizes due to its time complexity:

```python
class Solution:
    def countBadPairs(self, nums: List[int]) -> int:
				n = len(nums)
				bad_pairs = 0

				for i in range(n):
						for j in range(i + 1, n):
								if i < j and (j - i != nums[j] - nums[i]):
										bad_pairs += 1

				return bad_pairs
```

This approach has a time complexity of **O(n²)** because of the nested loops. For small lists, this might work fine, but as `n` grows, it quickly becomes impractical.

## Can We Make It More Efficient?

Yes! Instead of counting bad pairs directly, it’s easier to count **good pairs** (i.e., pairs that satisfy the condition `j - i == nums[j] - nums[i]`) and subtract that count from the total number of possible pairs.

### Observing the Pattern

Notice that the condition `(j - i != nums[j] - nums[i])` is equivalent to:

```text
nums[i] - i != nums[j] - j
```

Thus, we can keep track of `nums[i] - i` using a **HashMap (dictionary in Python)** to count how often each difference appears.

### Calculating Total Pairs

The total number of pairs in any list of length `n` is:

```text
total_pairs = n * (n - 1) // 2
```

### The Optimized Approach

1. Use a dictionary `diff_count` to track how many times each difference `diff = nums[i] - i` has appeared.
2. For each element in the list, if `diff` has been seen before, it means there exists some `j < i` such that `nums[i] - i == nums[j] - j`. This contributes to the count of good pairs.
3. After checking, update the dictionary with the current `diff`.
4. Finally, calculate the number of bad pairs by subtracting the count of good pairs from the total number of pairs:

```python
from collections import defaultdict

class Solution:
    def countBadPairs(self, nums: List[int]) -> int:
        n = len(nums)

        # Total possible pairs
        total_pairs = n * (n - 1) // 2

        # Map to store the frequency of (nums[i] - i)
        diff_count = defaultdict(int)

        # Count good pairs
        good_pairs = 0

        for i in range(n):
            # Compute the difference
            diff = nums[i] - i

            # If the difference has been seen before, it contributes to good pairs
            if diff in diff_count:
                good_pairs += diff_count[diff]

            # Update the count of this difference
            diff_count[diff] += 1

        # Bad pairs are total pairs minus good pairs
        num_bad_pairs = total_pairs - good_pairs

        return num_bad_pairs
```

### Complexity Analysis

- **Time Complexity:** `O(n)` – We iterate through the list once, and each dictionary operation takes constant time on average.
- **Space Complexity:** `O(n)` – We store at most `n` unique differences in the dictionary.

## Trading Space for Time

In the brute-force approach, we had:

- **Time Complexity:** `O(n²)`
- **Space Complexity:** `O(1)`

In the optimized approach, we traded additional space for a dictionary (`O(n)` space complexity) to reduce the time complexity to `O(n)`. This trade-off is worth it when the input size grows large because the gain in time efficiency is significant.

## Conclusion

This example illustrates how **trading space for time** can drastically improve algorithm performance. By using a HashMap to store intermediate results, we reduced the time complexity from `O(n²)` to `O(n)`, making our solution more scalable and practical for large inputs.

In algorithm design, always ask yourself: _"Can I use extra space to reduce the time complexity?"_ Often, the answer leads to a more efficient and elegant solution.
